---
layout: post
title: Spark 深入 RDD
categories: [Spark,大数据]
description: RDD 弹性分布式数据集
keywords: 大数据,Spark,Java
---

# Spark 深入理解

>本文大部分内容取自参考链接,谢谢 张逸 的精彩分享.

与许多专有的大数据处理平台不同，Spark建立在统一抽象的RDD之上，使得它可以以基本一致的方式应对不同的大数据处理场景，包括MapReduce，Streaming，SQL，Machine Learning以及Graph等。这即Matei Zaharia所谓的“设计一个通用的编程抽象（Unified Programming Abstraction）。这正是Spark这朵小火花让人着迷的地方。

要理解Spark，就需得理解RDD。

## 一.RDD是什么？
RDD，全称为Resilient Distributed Datasets，是一个容错的、并行的数据结构，可以让用户显式地将数据存储到磁盘和内存中，并能控制数据的分区。同时，RDD还提供了一组丰富的操作来操作这些数据。

1. 转化(transformation):诸如map、flatMap、filter等转换操作实现了monad模式，很好地契合了Scala的集合操作,Java也不差的。
2. 执行(action):诸如join、groupBy、reduceByKey等更为方便的操作（注意，reduceByKey是action，而非transformation），以支持常见的数据运算。

通常来讲，针对数据处理有几种常见模型，包括：

1. Iterative Algorithms(迭代计算)
2. Relational Queries(关联查询)
3. MapReduce()
4. Stream Processing(流式处理)

例如Hadoop MapReduce采用了MapReduces模型，Storm则采用了Stream Processing模型。RDD则混合了这四种模型，使得Spark可以应用于各种大数据处理场景。是不是想起了 Redis丰富的数据结果.

## 二.RDD数据结构
RDD作为数据结构，本质上是一个只读的分区记录集合。一个RDD可以包含多个分区，每个分区就是一个dataset片段。RDD可以相互依赖。

1. 窄依赖（narrow dependencies）：子RDD的每个分区依赖于常数个父分区（即与数据规模无关）；
2. 宽依赖（wide dependencies）：子RDD的每个分区依赖于所有父RDD分区。

例如map操作会产生narrow dependency，而join操作则产生wide dependency。

Spark之所以将依赖分为narrow与wide，基于两点原因。

1. 首先，narrow dependencies可以支持在同一个cluster node上以管道形式执行多条命令，例如在执行了map后，紧接着执行filter。相反，wide dependencies需要所有的父分区都是可用的，可能还需要调用类似MapReduce之类的操作进行跨节点传递。
2. 其次，则是从失败恢复的角度考虑。narrow dependencies的失败恢复更有效，因为它只需要重新计算丢失的parent partition即可，而且可以并行地在不同节点进行重计算。而wide dependencies牵涉到RDD各级的多个Parent Partitions。

下图说明了narrow dependencies与wide dependencies之间的区别：图中，

- 一个灰色虚线框一个表示阶段:Stage 
- 一个蓝色实现框表示一个RDD:A,B,C,D,E,F,G
，一个黑色或者蓝色的矩形代表一个partition。
![](http://cdn3.infoqstatic.com/statics_s2_20170228-0434_4/resource/articles/spark-core-rdd/zh/resources/1rdd_stage.jpg)

## 三.RDD如何保障数据处理效率？

## 四.RDD对容错的支持
支持容错通常采用两种方式：数据复制或日志记录。对于以数据为中心的系统而言，这两种方式都非常昂贵，因为它需要跨集群网络拷贝大量数据，毕竟带宽的数据远远低于内存。

RDD天生是支持容错的。首先，它自身是一个不变的(immutable)数据集，其次，它能够记住构建它的操作图（Graph of Operation），因此当执行任务的Worker失败时，完全可以通过操作图获得之前执行的操作，进行重新计算。由于无需采用replication方式支持容错，很好地降低了跨网络的数据传输成本。

不过，在某些场景下，Spark也需要利用记录日志的方式来支持容错。例如，在Spark Streaming中，针对数据进行update操作，或者调用Streaming提供的window操作时，就需要恢复执行过程的中间状态。此时，需要通过Spark提供的checkpoint机制，以支持操作能够从checkpoint得到恢复。

针对RDD的wide dependency，最有效的容错方式同样还是采用checkpoint机制



## 参考
1. [理解Spark的核心RDD](http://www.infoq.com/cn/articles/spark-core-rdd)
2. [Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing](chrome-extension://ikhdkkncnoglghljlkmcimlnlhkeamad/pdf-viewer/web/viewer.html?file=http%3A%2F%2Flitaotao.github.io%2Ffiles%2Fspark-rdd-paper.pdf)
3. [RDD：基于内存的集群计算容错抽象](http://shiyanjun.cn/archives/744.html)